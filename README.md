
# Deep Reinforcement Learning

Deep learning is a type of [machine learning](https://en.wikipedia.org/wiki/Machine_learning), which is a type of [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence).

Combining Deep Learning with Reinforcement Learning Algorithm leads to Deep Reinforcement Learning. This repository contains my learning progress in Deep Reinforcement Learning.

## Table of Contents

### Projects

The projects that are contained in this repro can be found below.  All of the projects use rich simulation environments from [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents).

* [Navigation](https://github.com/steffenkoerner/deep_reinforcement_learning/tree/main/projects/p1_navigation): This projects trains an agent to collect yellow bananas while avoiding blue bananas.
* [REINFORCE Algorithm](https://github.com/steffenkoerner/deep_reinforcement_learning/tree/main/projects/reinforce_algorithm): This project contains the implementation of the REINFORCE algorithm to solve the OpenAI CartPole environment
* [DDPG Algorithm](https://github.com/steffenkoerner/deep_reinforcement_learning/tree/main/projects/p2_continous_control): This project contains the implementation of the DDPG to solve the unity Reacher environment

### AI Resideny Programs
https://github.com/dangkhoasdc/awesome-ai-residency
### Additinal Resources

* [Cheatsheet](https://github.com/steffenkoerner/deep_reinforcement_learning/blob/main/cheatsheet.pdf): Contains a summary of all important reinforcement learning algorithms
* [Collection of Deep Learning Links](https://docs.google.com/spreadsheets/d/1NZtIxDWiJ_B0UKhIDUk-wTZAT3Fxfh-fGwcQKXg1bQU/edit#gid=0)
* [Open AI Deep Reinforcement Learning Literature](https://spinningup.openai.com/en/latest/index.html)
* [Roadmap from OpenAI to get an RL researcher](https://spinningup.openai.com/en/latest/spinningup/spinningup.html)

### Deep Reinforcement Learning
- [Deep Reinforcement Learning: Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)
- [Write an AI to win at Pong from scratch with Reinforcment Learning](https://medium.com/@dhruvp/how-to-write-a-neural-network-to-play-pong-from-scratch-956b57d4f6e0)
- [Conquering OpenAI Retro Contest 2: Demistifying Rainbow Baseline](https://medium.com/intelligentunit/conquering-openai-retro-contest-2-demystifying-rainbow-baseline-9d8dd258e74b)
- [Request for Research 2.0 OpenAI](https://openai.com/blog/requests-for-research-2/#cartpole)

## Research Papers
- [Human Level Control Through DRL](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)
- [Dueling Network Architectures for DRL](https://arxiv.org/abs/1511.06581)
- [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)
- [DRL with Double Q Learning](https://arxiv.org/abs/1509.06461)
- [Issues in Using Function Approximation in DRL](https://www.ri.cmu.edu/pub_files/pub1/thrun_sebastian_1993_1/thrun_sebastian_1993_1.pdf)
- [Asynchronous Methods for DRL](https://arxiv.org/abs/1602.01783)
- [A Distributional Perspective on RL](https://arxiv.org/abs/1707.06887)
- [Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295)
- [Rainbow: Combining Improvements in DRL](https://arxiv.org/abs/1710.02298)
- [Proximal Policy Optimization Algorithm](https://arxiv.org/abs/1707.06347)
- [Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic](https://arxiv.org/abs/1611.02247)#
- [A Deeper Look at Experience Replay](https://arxiv.org/pdf/1712.01275.pdf)
- [High-Dimensional Continuous Control Using Generalized Advantage Estimation](https://arxiv.org/abs/1506.02438)
- [Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971)
- [Benchmarking Deep Reinforcement Learning for Continuous Control](https://arxiv.org/abs/1604.06778)
- [Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments](https://proceedings.neurips.cc/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf)
- [Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm](https://arxiv.org/pdf/1712.01815.pdf)
- [Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control](https://arxiv.org/pdf/1708.04133.pdf)

## YouTube Videos
- [Deep RL Bootcamp Lecture 6: Nuts and Bolts of Deep RL Experimentation](https://www.youtube.com/watch?v=8EcdaCk9KaQ)
- [Deep RL Bootcamp Frontiers Lecture I: Recent Advances, Frontiers and Future of DRL](https://www.youtube.com/watch?v=bsuvM1jO-4w)
- [Deep Learning for Robotics - Prof. Pieter Abbeel - NIPS 2017 Keynote](https://www.youtube.com/watch?v=TyOooJC_bLY)



### Evolution Strategies
- [Evolution Strategies as a Scalable Alernative to Reinforcement Learning](https://openai.com/blog/evolution-strategies/)



### Neural Networks
- [Deep Learning Book (Ian Goodfellow)](http://www.deeplearningbook.org/)
- [Hackers Guide to Neural Networks](http://karpathy.github.io/neuralnets/)
- [Online Book Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)
- [Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap)
- [Google Crash Course](https://developers.google.com/machine-learning/crash-course/fitter/graph)
- [Neural Network Playground](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.30786&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)
- [Rules of Machine Learning](https://developers.google.com/machine-learning/guides/rules-of-ml/)
- [Free Udacity Course Deep Learning](https://eu.udacity.com/course/deep-learning--ud730?utm_medium=referral&utm_campaign=api)
- [Github code for applying style to images](https://github.com/lengstrom/fast-style-transfer)
- [An Insiderâ€™s Guide to Keeping Up with the AI Experts](https://blog.udacity.com/2018/09/machine-learning-ai-experts-on-twitter.html)
- [Understanding the difficulty of training deep feedforward neural networks](jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)
- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167v2.pdf)
- [Tips and Tricks](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html)



#### Backpropagation
- [Summary Backpropagation](https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/)
- [Backpropagation intuitve](http://colah.github.io/posts/2015-08-Backprop/)
- [Backpropagation in detail](http://neuralnetworksanddeeplearning.com/chap2.html)
- [Karpathy - Yes, you should understand backpropagation](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)
- [CS231n Winter 2016 Lecture 4 Backpropagation](https://www.youtube.com/watch?v=59Hbtz7XgjM)

### CNN
- [A easy introduction to CNN (youtube)](https://www.youtube.com/watch?v=2-Ol7ZB0MmU)
- [Convolutional Neuronal Network (CS231)](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
- [How CNN's see the world](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html)
- [What a neural net see](https://experiments.withgoogle.com/what-neural-nets-see)
- [Visualizing and Understanding Deep Neural Networks](https://www.youtube.com/watch?v=ghEmQSxT6tw&t=5s)
- [Deep Visualization Toolbox](https://www.youtube.com/watch?v=AgkfIQ4IGaM&t=78s)

### Capsule Networks
- [Blogpost Capsule Networks](https://cezannec.github.io/Capsule_Networks/)

### LSTM
- [Understanding LSTM ](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [Exploring LSTM](http://blog.echen.me/2017/05/30/exploring-lstms/)
- [CS231n Lecture 10 - Recurrent Neural Networks, Image Captioning, LSTM](https://www.youtube.com/watch?v=iX5V1WpxxkY)
- [Tutorial LSTM](https://skymind.ai/wiki/lstm)
- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- [How to Construct Deep Recurrent Neural Networks](https://arxiv.org/abs/1312.6026)

### Generative Adversarial Networks
- [Original Paper for GAN's](https://arxiv.org/abs/1406.2661)
- [Cycle GAN](https://arxiv.org/pdf/1703.10593.pdf)
- [LSGAN](https://arxiv.org/pdf/1611.04076.pdf)
 
 ### Optimization
 - [An overview of gradient descent optimization algorithm](https://ruder.io/optimizing-gradient-descent/)
#### Examples
- [Pix2Pix](https://affinelayer.com/pixsrv/)
- [Cycle GAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

### Environments
- [OpenAI gyms](https://gym.openai.com/)
- [Unity ML Engine](https://github.com/Unity-Technologies/ml-agents)
### Competitions
- [kaggle](https://www.kaggle.com/)

### Games
- [Flappy Bird(Github)](https://github.com/yenchenlin/DeepLearningFlappyBird)

### Machine Learning Projects
- [30 Amazing Machine Learning Projects](https://medium.mybridge.co/30-amazing-machine-learning-projects-for-the-past-year-v-2018-b853b8621ac7)

### Interview Machine Learning
- [What I am learned from AI interviews](https://blog.usejournal.com/what-i-learned-from-interviewing-at-multiple-ai-companies-and-start-ups-a9620415e4cc)


### Other Links
- [50 best public datasets for machine learning](https://towardsdatascience.com/the-50-best-public-datasets-for-machine-learning-d80e9f030279)



 ### Study Plan
 - [Study Plan for Machine Learning](https://github.com/ZuzooVn/machine-learning-for-software-engineers)
 - [Study Plan for Software Engineer](https://github.com/jwasham/coding-interview-university)
   - [10 Operating System Concepts to know](https://medium.com/cracking-the-data-science-interview/the-10-operating-system-concepts-software-developers-need-to-remember-480d0734d710)

## Unordered Content (Needs Clean Up !!!)
### Concept a ML Engineer must know
- Supervised Learning
- Unsupervised Learning
- Reinforcement Learning
- Backpropagation
- Gradient Decent, Stochastic Gradient Descent
  - Local Minima
  - Momentum
- Capsule Network
- Autoencoder
- Neural Network, MLP, CNN, RNN
- CNN
  - Convoluational Layer
  - Transposed Convolutional Layer
  - Pooling Layer
  - Padding
    - Adding border pixels around the image
  - Stride
- Regularization (L1, L2, Dropout)
- Vanishing Gradient
- Activation Function (Sigmoid, Relu,...)
- Learning Rate
- [Transfer Learning](http://cs231n.github.io/transfer-learning/)
  - use pre-trained networks to improve the performance of your classifier
  
  ### Interesting for blog
  - [Computational Graph Pytorch](https://stackoverflow.com/questions/63582590/why-do-we-call-detach-before-calling-numpy-on-a-pytorch-tensor)
  - [Pytorch autograd](https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95#:~:text=Gradients%20are%20calculated%20by%20tracing,way%20using%20the%20chain%20rule.)
  - [Pytorch Autograd Youtube Video](https://www.youtube.com/watch?v=MswxJw-8PvE)
  - [Deriving Policy Gradient](https://medium.com/@thechrisyoon/deriving-policy-gradients-and-implementing-reinforce-f887949bd63)
  - [Using Keras and Deep Deterministic Policy Gradient to play TORCS](https://yanpanlau.github.io/2016/10/11/Torcs-Keras.html)

  ### Other github resources
  - [RL-Adventure](https://github.com/higgsfield/RL-Adventure)
  - [Really cool implementaiton of different RL algorithm](https://github.com/ShangtongZhang/DeepRL)
  - [RL ALgorithm Libraries](https://github.com/vwxyzjn/cleanrl)
  - [Udactiy repro](https://github.com/udacity/deep-reinforcement-learning)
  - [Open AI Algorithm Implementation](https://github.com/openai/baselines)
  - [David Silver](https://github.com/dalmia/David-Silver-Reinforcement-learning)
  - [Denny Britz Reinforcement Learning](https://github.com/dennybritz/reinforcement-learning)
  - [DDPG Implementation](https://github.com/floodsung/DDPG)


  ### Skills a ML should have
- Building and training neural networks
- Model evaluation and validation
- Convolutional neural networks
- Autoencoders and feature extraction
- Transfer learning
- Recurrent neural networks
- Natural language processing
- Data augmentation
- Generative adversarial networks
- Hyperparameter tuning
- Model deployment and serving
    

### Brain Storming

## Steps to do deep learning
- Visualize Data
- Pre-Process Data (Filtering of bad examples, Appyling little changes, Normalizing,...)
- Define a Model
- Train the model (Defining loss and optimization functions)
- Save the best model
